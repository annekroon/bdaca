\section*{Before the course starts: Prepare your computer.}
\textsc{\ding{52} Chapter 1: Preparing your computer}\\
Follow all steps as outlined in Chapter 1.

\section*{Week 1: Introduction}
\subsection*{Monday, 1-4. Lecture.}
{\footnotesize{(Anne)}\\}

We discuss what Big Data means, how the concept can be understood, what challenges and opportunities arise, and what the implications are for communication science. 

Mandatory readings (in advance): \citealp{boyd2012}, \citealp{Kitchin2014}. 

Additional literature, not obligatory to read in advance, but very informative: \citealp{Mahrt2013}, \citealp{Vis2013}, \citealp{Trilling2017a}.

%The articles mentioned above discuss the implications of Big Data methods in a very broad way. You should also have a look at some applied articles in the field to get an idea of the type of research that is currently conducted in the field. Good readings are \citealp{Castillo2014,Ellison2013,Conover2012}. You do not have to read all of them in detail, but should get a general understanding of the types of methods that are used in these studies.


\subsection*{Thursday, 4--4. Lab session.}
\textsc{\ding{52} Chapter 2: The Linux command line}\\
\textsc{\ding{52} Chapter 3: A language, not a program}\\
{\footnotesize{(Anne)}\\}
We will get familiar with the Virtual Machine and the software we will work with. Make sure you installed everything in advance and that you can start up your machine. 


\section*{Week 2: Getting started with Python}

\subsection*{Monday, 8--4. Lecture.}
\textsc{\ding{52} Chapter 4: The very, very basics of programming in Python}\\
{\footnotesize{(Anne)}\\}
You will get a very gentle introduction to computer programming. During the lecture, you are encouraged to follow the examples on your own laptop.

\subsection*{Thursday, 11--4. Lab session.}
\textsc{\ding{52} Appendix A: Exercise 1}\\
{\footnotesize{(Anne)}\\}
We will do our first real steps in Python and do some exercises to get the feeling. 


\section*{Week 3: Data harvesting and storage}
This week is about data sources and their (dis)advantages. 

\subsection*{Monday, 15--4. Lecture.}
{\footnotesize{(Anne)}\\}
A conceptual overview of APIs, scrapers, crawlers, RSS-feeds, databases, and different file formats.

Read the article by \cite{Morstatter2013} in advance. It discusses the quality of data provided by the Twitter API. As a practical example for how ``dirty'' input data (i.e., data that for whatever reason does not come in form of a clean, structured data set like a table) can be parsed and preprocessed, have a look at the method section of the article by \cite{Lewis2013}. 


\subsection*{Thursday, 18--4. Lab session.}
\textsc{\ding{52} Chapter 5.1--5.3: Retrieving and storing data}\\
{\footnotesize{(Anne)}\\}
We will write a script to collect some data. 

\section*{Week 4: Sentiment analysis}
Up till now, we have mainly talked about available data and how to acquire them. From now on, we will focus on analyzing them and cover one technique per week. By now, you should also have gotten some idea about your final project.

\subsection*{Monday, 22--4. Holiday (Easter)}

\subsection*{Thursday, 25--4. Lecture.}
{\footnotesize{(Anne)}\\}
We start with an overview of different analytical approaches which we will cover in the next weeks, After that, we will focus on the first of these techniques, sentiment analysis.

Read the following two articles in advance. The first one gives an overview of how to analyze social media data, in this case, Twitter \citep{Bruns2013}. The other one is an example of a sentiment analysis \citep{Mostafa2013}.

Some additional examples of sentiment analysis (not obligatory): \cite{Huang2007,Pestian2012}. If you want to have a look under the hood of a popular sentiment analysis algorithm, you can read \cite{Thelwall2012} and \cite{Hutto2014}.



\section*{Week 5: Automated content analysis with NLP and regular expressions}
Text as written by humans usually is pretty messy. You will learn how to process text to make it suitable for further analysis by using techniques of Natural Language Processing (NLP), and how to extract meaningful information (discarding the rest) using regular expressions.



\subsection*{Monday, 29--4. Lab session (accompanying Lecture week 4).}
\textsc{\ding{52} Chapter 6: Sentiment analysis}\\
{\footnotesize{(Anne)}\\}
You will write a tool to read data and conduct a sentiment analysis.

\subsection*{Thursday, 2--5. Lecture with exercises}
\textsc{\ding{52} Chapter 7: Automated content analysis}\\
{\footnotesize{(Anne)}\\}
This lecture will introduce you to techniques and concepts like stemming, stopword removal, n-grams, word counts and word co-occurrances, and regular expressions. We will do some exercises during the lecture.

Preparation: Mandatory reading: \citealp{Boumans2016}. Also read the paper by \cite{Madnani}. It uses the same package (NLTK) which we use in class, If you don’t get all practical details yet, that’s OK. Pay special attention to the (linguistic) concepts applied.  

\subsection*{Take-home exam}
In week 5, the midterm take-home exam is distributed after the Thursday meeting. The answer sheets and all files have to be handed in no later than the day before the next meeting, i.e. Sunday evening (5--5, 23.59).

\section*{Week 6: Web scraping and parsing}

\subsection*{Monday, 6--5. Lecture.}
{\footnotesize{(Anne)}\\}
We will explore techniques to download data from web pages and to extract meaningful information like the text (or a photo, or a headline, or the author) from an article on \url{http://nu.nl}, a review (or a price, or a link) from \url{http://kieskeurig.nl}, or similar. 

\subsection*{Thursday, 9--5. Lab session}
\textsc{\ding{52} Chapter 8: Web scraping}\\
{\footnotesize{(Anne)}\\}
We will exercise with web scraping and parsing.

\section*{Week 7: Statistics, Machine Learning, and what to do next}

\subsection*{Monday, 13--5. Short lecture plus lab session.}
\textsc{\ding{52} Section 3.5: Jupyter Notebook}\\
\textsc{\ding{52} Chapter 12: Statistics with Python}\\
{\footnotesize{(Anne)}\\}
You have worked hard so far, so we'll do something fun and relaxing (of course, fun might be a relative concept in this course\ldots). You are going to learn how to create visualizations, do conventional statistical tests, manage datasets with Python, save the results together with your code and your own explanations -- and all of this within your browser.

\subsection*{Thursday, 16--5. Lecture}

{\footnotesize{(Anne)}\\}
This lecture will introduce you to one of the most fascinating topics in automated content analysis: machine learning. I will walk you trough the ideas behind unsupervised and supervised machine learning. The nice thing is that you actually have already done it during your studies: Principal component analysis is a form of unsupervised ML and regression analysis a form of supervised ML -- you just never called it like this. And you probably never thought about using these techniques to analyze texts (or images). And that's what we are going to do.
We will not be able to do all of this in this course, but you learn where to look for resources in case you want to go on with computational methods.

\section*{Finish!}
This week is designated to working on your final projects. 

\subsection*{Monday, 20--5. Open Lab (not mandatory)}
{\footnotesize{(Anne)}\\}
Possibility to ask last questions regarding the final project.

\subsection*{Final project}
Deadline for handing in: Wednesday, 29--5, 23.59.
